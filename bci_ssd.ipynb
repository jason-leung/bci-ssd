{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hEFFhNUAzxS"
   },
   "source": [
    "BCI Sample Size Determination (SSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHNynl6mD3l9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "from scipy import special\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U1ofKEsyefrv"
   },
   "outputs": [],
   "source": [
    "# sample size\n",
    "n_subjects = [4, 8, 12, 16, 24] # number of subjects\n",
    "n_trials = [20, 36, 64] # number of trials\n",
    "\n",
    "M = 500 # iterations\n",
    "\n",
    "# MCMC\n",
    "n_samples = 5000\n",
    "n_chains = 3\n",
    "n_tune = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-v6WURLTeuCm",
    "outputId": "39befe68-cb90-4e17-c698-471b7a13857b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for Ns in n_subjects:\n",
    "    ALCs = []\n",
    "    for T in n_trials:\n",
    "        ALC = 0\n",
    "        for m in range(M):\n",
    "            print(\"M: \"+str(m)+\"\\t Ns: \"+str(Ns)+\"\\t T: \"+str(T))\n",
    "            \n",
    "            # draw parameters (theta hat) from sampling prior\n",
    "            print(\"Step 1: draw parameters from sampling prior\")\n",
    "            mu_phi = np.random.uniform(0.55, 0.95)\n",
    "            mu_alpha = special.logit(mu_phi)\n",
    "            sigma_alpha = np.random.uniform(0.2, 1.2)\n",
    "            \n",
    "            alpha = np.random.normal(mu_alpha, sigma_alpha, Ns)\n",
    "            phi = special.expit(alpha)\n",
    "            \n",
    "            # draw dataset D^(n) from sampling distribution\n",
    "            print(\"Step 2: draw data from sampling distribution\")\n",
    "            y = np.random.binomial(T, phi) # vector of size Ns\n",
    "            \n",
    "            # compute delta(D^(n)) using Baye's rule (via MCMC)\n",
    "            print(\"Step 3: compute delta using Baye's rule (via MCMC)\")\n",
    "            with pm.Model() as model:\n",
    "                # priors for group level parameters - a single value for mean and std\n",
    "                group_level_mean_logit = pm.Normal('μ_α', mu=0, sd=2**0.5)\n",
    "                group_level_std_logit = pm.Uniform('σ_α', lower=0., upper=10.)\n",
    "                \n",
    "                group_level_mean_prob = pm.Deterministic('μ_φ', pm.math.invlogit(group_level_mean_logit))\n",
    "                \n",
    "                # subject level parameters - vector of size Ns\n",
    "                subject_level_accuracy_logit = pm.Normal('α', mu=group_level_mean_logit, sd=group_level_std_logit, shape=Ns)\n",
    "                subject_level_accuracy_prob = pm.Deterministic('φ', pm.math.invlogit(subject_level_accuracy_logit))\n",
    "                \n",
    "                # likelihood (sampling distributions) of observations\n",
    "                y_obs = []\n",
    "                for s in range(Ns):\n",
    "                    y_obs_i = pm.Binomial('y_obs_'+str(s), n=T, p=subject_level_accuracy_prob[s], observed=y[s])\n",
    "                    y_obs.append(y_obs_i)\n",
    "                \n",
    "                # draw posterior samples\n",
    "                trace = pm.sample(n_samples, chains=n_chains, tune=n_tune, discard_tuned_samples=True)\n",
    "            \n",
    "            # posterior analysis\n",
    "            trace_np = pd.DataFrame(trace['α']).to_numpy() # 15000 x Ns array of subject-level accuracies\n",
    "            \n",
    "            # take mean across all Ns subjects --> vector of 15000\n",
    "            group_level_mean_logit_hat = np.mean(trace_np, axis=1)\n",
    "            \n",
    "            # compute 95% CI\n",
    "            delta = np.percentile(group_level_mean_logit_hat, 97.5) - np.percentile(group_level_mean_logit_hat, 2.5)\n",
    "            print(\"delta:\", delta)\n",
    "\n",
    "            # approximate ALC\n",
    "            ALC += delta\n",
    "        ALC /= M\n",
    "        print(\"ALC:\", ALC)\n",
    "        ALCs.append(ALC)\n",
    "    plt.plot(n_trials, ALCs, marker='x', label='Ns = '+str(Ns))\n",
    "\n",
    "plt.xlabel('Number of trials T')\n",
    "plt.ylabel('Average 95% CI width ALC(n)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BCI Sample Size Determination_NEW",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
